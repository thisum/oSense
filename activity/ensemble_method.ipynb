{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy import fftpack\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (37260, 16)    test size: (18630, 16)\n",
      "\n",
      "NN score: 0.574503488996\n"
     ]
    }
   ],
   "source": [
    "#pose estimation\n",
    "train = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "\n",
    "test = pd.read_csv(\"../data/ensemble/pose/samitha_q_test.txt\", header=None)\n",
    "train = pd.read_csv(\"../data/ensemble/pose/samitha_q_train.txt\", header=None)\n",
    "\n",
    "train_df = train.sample(frac=1).reset_index(drop=True)\n",
    "test_df = test.sample(frac=1).reset_index(drop=True)\n",
    "print(\"train size: \" + str(train.shape) + \"    test size: \" + str(test.shape))\n",
    "\n",
    "\n",
    "x_test = test_df.loc[:, :14]\n",
    "y_test = test_df.loc[:, 15]\n",
    "\n",
    "x_train = train_df.loc[:, :14]\n",
    "y_train = train_df.loc[:, 15]\n",
    "\n",
    "x_combined = x_train.append(x_test)\n",
    "x_combined = (x_combined - x_combined.mean()) / x_combined.std() + 0.000001\n",
    "x_combined = x_combined.reset_index(drop=True)\n",
    "\n",
    "x_train = x_combined.loc[:x_train.shape[0] - 1, :]\n",
    "x_test = x_combined.loc[x_train.shape[0]:, :]\n",
    "\n",
    "p_x_test = x_test\n",
    "p_y_test = y_test\n",
    "\n",
    "nn_score = 0.0\n",
    "pose_model = None\n",
    "for i in range(10):\n",
    "    clf = MLPClassifier(activation='relu', hidden_layer_sizes=(200, 200), max_iter=200000, learning_rate='adaptive', early_stopping=False)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    if score > nn_score:\n",
    "        nn_score = score\n",
    "        pose_model = clf\n",
    "\n",
    "print('\\nNN score: ' + str(nn_score))\n",
    "pkl_filename = \"pose_pickle.pkl\"  \n",
    "with open(pkl_filename, 'wb') as file:  \n",
    "    pickle.dump(pose_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (35280, 26)    test size: (17640, 26)\n",
      "NN score: 0.656179138322\n"
     ]
    }
   ],
   "source": [
    "#activity\n",
    "test = pd.read_csv(\"../data/ensemble/activity/samitha_test.txt\", header=None)\n",
    "train = pd.read_csv(\"../data/ensemble/activity/samitha_train.txt\", header=None)\n",
    "\n",
    "train_df = train.sample(frac=1).reset_index(drop=True)\n",
    "test_df = test.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(\"train size: \" + str(train.shape) + \"    test size: \" + str(test.shape))\n",
    "\n",
    "x_test = test_df.loc[:,:24]\n",
    "y_test = test_df.loc[:,25]\n",
    "\n",
    "x_train = train_df.loc[:,:24]\n",
    "y_train = train_df.loc[:,25]\n",
    "\n",
    "x_combined = x_train.append(x_test)\n",
    "x_combined =(x_combined-x_combined.mean())/x_combined.std()+0.000001\n",
    "x_combined = x_combined.reset_index(drop=True)\n",
    "\n",
    "x_train = x_combined.loc[:x_train.shape[0]-1, :]\n",
    "x_test = x_combined.loc[x_train.shape[0]:, :]\n",
    "\n",
    "a_x_test = x_test\n",
    "a_y_test = y_test\n",
    "    \n",
    "nn_score = 0.0\n",
    "activity_model = None\n",
    "for i in range(10):\n",
    "    clf = MLPClassifier(activation='relu', hidden_layer_sizes=(100, 100), max_iter=200000, learning_rate='adaptive',\n",
    "                        early_stopping=False)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    if score > nn_score:\n",
    "        nn_score = score\n",
    "        activity_model = clf\n",
    "\n",
    "print('NN score: ' + str(nn_score))  \n",
    "pkl_filename = \"activity_pickle.pkl\"  \n",
    "with open(pkl_filename, 'wb') as file:  \n",
    "    pickle.dump(activity_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posture\n",
      "0.574503488996\n",
      "[[1977    0    0    0    0    5    0    0    0   18]\n",
      " [   0   30   10 1960    0    0    0    0    0    0]\n",
      " [   0  846 1057   97    0    0    0    0    0    0]\n",
      " [   0 1878    0  122    0    0    0    0    0    0]\n",
      " [   0    0    0    0 2000    0    0    0    0    0]\n",
      " [ 416    0    0    0    0  144    0    0    0   70]\n",
      " [   0    0    0    0    0    0 1929    0    2   69]\n",
      " [   0    0  409    0  278    0    0 1313    0    0]\n",
      " [ 565   52  192   16    3    2   25    0 1081   64]\n",
      " [  30   87    7   74    0  745    0    0    7 1050]]\n"
     ]
    }
   ],
   "source": [
    "print(\"posture\")\n",
    "p_y_pred = pose_model.predict(p_x_test)\n",
    "print(accuracy_score(p_y_test, p_y_pred))\n",
    "print(confusion_matrix(p_y_test, p_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.656179138322\n",
      "[[1666    4   56   14    1   47    0  113    0    0]\n",
      " [   0 1514  338   49    0    0    0    0    0    0]\n",
      " [   0    0 1901    0    0    0    0    0    0    0]\n",
      " [  17   15  152 1642    2    5    0    3   60    5]\n",
      " [1519    9    0    0  290    1    0   77    5    0]\n",
      " [   3   13    0   49   13  234  146    0   73    0]\n",
      " [   0    0    0    0    0   14 1887    0    0    0]\n",
      " [   3    0    0    0   23    0    0 1846   29    0]\n",
      " [  92   21    0  928   38  137    0    0  586   99]\n",
      " [  31    0    0    0  257    0    0  973  631    9]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"activity_pickle.pkl\", 'rb') as file:  \n",
    "    activity_pickle = pickle.load(file)\n",
    "\n",
    "a_y_pred = activity_pickle.predict(a_x_test)\n",
    "print(accuracy_score(a_y_test, a_y_pred))\n",
    "print(confusion_matrix(a_y_test, a_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activity\n",
      "0.638492063492\n",
      "[[1686    7  110   25    0    5    0   68    0    0]\n",
      " [   0 1444  389   68    0    0    0    0    0    0]\n",
      " [   0    0 1899    0    0    2    0    0    0    0]\n",
      " [  11   33  139 1595   13    1    0    0   80   29]\n",
      " [1422    6    0    4  423    0    0   39    7    0]\n",
      " [  11   19    0   50   55  185  164    0   47    0]\n",
      " [   0    0    0    0    0   12 1889    0    0    0]\n",
      " [  33    0    7    0   36    0    0 1612  213    0]\n",
      " [ 120   12    0  962   54  105    0    0  523  125]\n",
      " [  28    0    0    0  204    0    0  848  814    7]]\n"
     ]
    }
   ],
   "source": [
    "print(\"activity\")\n",
    "a_y_pred = activity_model.predict(a_x_test)\n",
    "print(accuracy_score(a_y_test, a_y_pred))\n",
    "print(confusion_matrix(a_y_test, a_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "bottle_drinking                     2000\n",
      "hammer_hammering                    2000\n",
      "knife_chopping                      2000\n",
      "knife_cutting                       2000\n",
      "mug_drinking                        2000\n",
      "none                                 630\n",
      "pen_writing                         2000\n",
      "saw_sawing                          2000\n",
      "screwdriver_screwing(no-release)    2000\n",
      "spoon_stirring                      2000\n",
      "dtype: int64\n",
      "25\n",
      "bottle_drinking                  1901\n",
      "hammer_hammering                 1901\n",
      "knife_chopping                   1901\n",
      "knife_cutting                    1901\n",
      "mug_drinking                     1901\n",
      "none                              531\n",
      "pen_writing                      1901\n",
      "saw_sawing                       1901\n",
      "screwdriver_screwing(release)    1901\n",
      "spoon_stirring                   1901\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dat1 = a_x_test.reset_index(drop=True)\n",
    "dat2 = a_y_test.reset_index(drop=True)\n",
    "activity_test = pd.concat([dat1, dat2], axis=1)\n",
    "\n",
    "dat1 = p_x_test.reset_index(drop=True)\n",
    "dat2 = p_y_test.reset_index(drop=True)\n",
    "pose_test = pd.concat([dat1, dat2], axis=1)\n",
    "\n",
    "print(pose_test.groupby([15]).size())\n",
    "print(activity_test.groupby([25]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1901, 16)\n",
      "(1901, 26)\n"
     ]
    }
   ],
   "source": [
    "p_test = pose_test[pose_test[15].isin(['spoon_stirring'])]\n",
    "p_test = p_test.iloc[99:, :]\n",
    "p_test = p_test.reset_index(drop=True)\n",
    "a_test = activity_test[activity_test[25].isin(['spoon_stirring'])]\n",
    "a_test = a_test.reset_index(drop=True)\n",
    "\n",
    "p_x_test = p_test.loc[:,:14]\n",
    "p_y_test = p_test.loc[:,15]\n",
    "\n",
    "a_x_test = a_test.loc[:,:24]\n",
    "a_y_test = a_test.loc[:,25]\n",
    "\n",
    "p_y_pred = pose_model.predict(p_x_test)\n",
    "p_score = accuracy_score(p_y_test, p_y_pred)\n",
    "\n",
    "a_y_pred = activity_model.predict(a_x_test)\n",
    "a_score = accuracy_score(a_y_test, a_y_pred)\n",
    "\n",
    "p = pose_model.predict_proba(p_x_test)\n",
    "a = activity_model.predict_proba(a_x_test)\n",
    "\n",
    "print(p_test.shape)\n",
    "print(a_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_list = ['DB', 'HA', 'CH', 'CK', 'DM', 'RE', 'WR', 'SA', 'SC', 'ST']\n",
    "posture_list = ['DB', 'HA', 'CH', 'CK', 'DM', 'RE', 'WR', 'SA', 'SC', 'ST']\n",
    "results = []\n",
    "result_df = pd.DataFrame(columns=['activity', 'posture', 'ensemble'])\n",
    "os.remove('ensemble_result.csv')\n",
    "\n",
    "for r in range(p.shape[0]):\n",
    "    \n",
    "    activity_accuracy = []\n",
    "    posture_accuracy = []\n",
    "    prediction = ''\n",
    "\n",
    "    for i in range(p[r].shape[0]):\n",
    "        posture_accuracy.append((posture_list[i], p[r][i]))\n",
    "\n",
    "    for i in range(a[r].shape[0]):\n",
    "        activity_accuracy.append((activity_list[i], a[r][i]))\n",
    "\n",
    "    max_activity = sorted(activity_accuracy,key=lambda x: x[1], reverse=True)[:3]\n",
    "    max_posture = sorted(posture_accuracy,key=lambda x: x[1], reverse=True)[:3]\n",
    "    \n",
    "    if max_posture[0][0] in (['DB', 'DM', 'WR']) and max_posture[0][1]>0.95:\n",
    "        prediction = max_posture[0][0]\n",
    "     \n",
    "    elif max_posture[0][1] > max_activity[0][1] and max_activity[0][1] - max_activity[1][1] < 0.9:\n",
    "        prediction = max_posture[0][0]\n",
    "    else:\n",
    "        if max_activity[0][1] - max_activity[1][1] > 0.8:\n",
    "            prediction = max_activity[0][0]\n",
    "        elif max_posture[0][1] > 0.5:\n",
    "            prediction = max_posture[0][0]\n",
    "        else:\n",
    "            prediction = max_activity[0][0]\n",
    "            \n",
    "    result_df = result_df.append({'activity': max_activity[0][0], 'posture':max_posture[0][0], 'ensemble':prediction},  ignore_index=True)\n",
    "\n",
    "    results.append(str(max_activity) + \"|\" + str(max_posture))\n",
    "    line = str(max_activity) + ',' + str(max_posture)\n",
    "    with open('ensemble_result.csv', \"a\") as write_file:\n",
    "        line = line.replace(\"[\", \"\").replace(\"]\", \"\").replace('\\'', '').replace('(', '').replace(')', '')\n",
    "        write_file.write(line + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ensemble\n",
       "CK      7\n",
       "DB     19\n",
       "DM    119\n",
       "HA     17\n",
       "RE    118\n",
       "SA    769\n",
       "SC    709\n",
       "ST    143\n",
       "dtype: int64"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posture\n",
      "BO    1859\n",
      "SP      42\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(result_df.groupby(['posture']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble\n",
      "BO    1827\n",
      "KP      46\n",
      "KT       8\n",
      "RE       2\n",
      "SA      14\n",
      "SP       4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(result_df.groupby(['activity']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_list = ['knife_cutting', 'hammer_hammering', 'pen_writing', 'mug_drinking', 'spoon_stirring',\n",
    "            'saw_sawing', 'screwdriver_screwing(release)', 'knife_chopping', 'bottle_drinking', 'none']\n",
    "\n",
    "pose_list = ['knife_cutting', 'hammer_hammering', 'pen_writing', 'mug_drinking', 'spoon_stirring',\n",
    "            'saw_sawing', 'screwdriver_screwing(no-release)', 'knife_chopping', 'bottle_drinking', 'none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knife_cutting\n",
      "knife_cutting\n",
      "\n",
      "\n",
      "hammer_hammering\n",
      "hammer_hammering\n",
      "\n",
      "\n",
      "pen_writing\n",
      "pen_writing\n",
      "\n",
      "\n",
      "mug_drinking\n",
      "mug_drinking\n",
      "\n",
      "\n",
      "spoon_stirring\n",
      "spoon_stirring\n",
      "\n",
      "\n",
      "saw_sawing\n",
      "saw_sawing\n",
      "\n",
      "\n",
      "screwdriver_screwing(release)\n",
      "screwdriver_screwing(no-release)\n",
      "\n",
      "\n",
      "knife_chopping\n",
      "knife_chopping\n",
      "\n",
      "\n",
      "bottle_drinking\n",
      "bottle_drinking\n",
      "\n",
      "\n",
      "none\n",
      "none\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(activity_list[i])\n",
    "    print(pose_list[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
